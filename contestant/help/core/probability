Core Probability Help       Tue Dec 11 06:59:04 EST 2012


Probabilities
-------------

Probabilities are ratios of unbounded counts.

Suppose we have an experiment that we can run over and
over again, and which has N possible outcomes, o1, o2,
..., oN.  Think of an N-sided die that can be thrown
over and over again.

Suppose that after the first M repetitions of the
experiment (e.g., die throws) the number of times each
outcome has been observed are c1, c2, ..., cN, respec-
tively.  Then we look at the ratios

	p1 = c1/M, p2 = c2/M, ..., pN = cN/M

and see how these ratios change as we keep repeating
the experiment and increasing M.  If these ratios tend
to converge to particular numbers that we call `limits',
we say that these limits are the `probabilities' of the
outcomes, and write p1, p2, ..., pN to denote these
limits, i.e., these probabilities.

So for example, if the experiment consists of throwing
a normal 6-sided dice, we might expect all the outcome
probabilities to converge to 1/6, so we get

	p1 = p2 = p3 = p4 = p5 = p6 = 1/6

But things might not be thus, so let us look at what
else might happen.

One possibility is that the ratios converge but not
to equal values, so maybe

    p1 = 5/60, p2 = 15/60, p3 = p4 = p5 = p6 = 10/60

in which case throwing a 1 is less likely than one
would expect and throwing a 2 more likely.  In this
case the probabilities are still well defined, but
they differ from what we expected.  For dice we say
that a die is `unbiased' if all the probabilities
are equal, and `biased' if they are not.  Gamblers
may try to cheat by using biased dice which they
falsely claim are unbiased, for example.

The other possibility is the that ratios do NOT con-
verge to particular numbers, but tend to wander about
over a range of values as M, the number of experiments
(e.g., die throws) increases.  Then the probabilities
are UNDEFINED.  For example, you are gambling with a
cheater who has magnetised the die and put an electro-
magnet under the table which he controls with a foot
switch.  You can say if you like that there is an
external factor, the switch position, that affects the
probabilities, but if you don't know what the external
factors are, and they keep changing while you repeat
the experiment, then all you see is ratios that refuse
to converge.


Activities and Events
---------- --- ------

We are going to make an important change in terminology.

First, instead of an `experiment' we are going to talk
about an `activity'.  Second, instead of an `outcome'
we are going to talk about an `event' that happens
during the activity.

For example, suppose the activity consists of throwing
a 6-sided die TWICE.  Some events in this are:

   1.	Throwing a 1 with the first throw.
   .1	Throwing a 1 with the second throw.
   12   Throwing a 1 with the first throw and then
   	throwing 2 with the second throw.
   ij	Throwing an i with the firs throw and a j with
        the second throw, where 1 <= i,j <= 6.
   ==	Throwing the same number with both throws.

Note that

  1. is the union of 11, 12, 13, 14, 15, and 16.
  .1 is the union of 11, 21, 31, 41, 51, and 61.
  == is the union of 11, 22, 33, 44, 55, and 66.

Now to define probabilities one must repeat the activity
a very large number of times.  We generally do NOT talk
about this, and merely imply it.  We assume the activity
is repeatable in principal, though usually it is not
repeated in practice.

Furthermore, we assume that if we did repeat the
activity, then the probability ratios will converge to
limits.  Thus if cE is the number of times event E
happens when repeating the activity M times, we assume
that pE = cE/M converges to a limit, and we call this
limit the probability of event E in the activity.

The main point is that if you can compute the counts
of activity events you can compute the probabilities,
if they exist.

So to consider some events in our example, clearly

    c1. + c2. + c3. + c4. + c5. + c6. = M
so
    p1. + p2. + p3. + p4. + p5. + p6. = 1

Also, assuming that the die is unbiased is the same
as assuming that we will get the same probabilities
if we renumber the sides of the die, so in this case

    p1. = p2. = p3. = p4. = p5. = p6.

and given that these sum to 1, they all must = 1/6.

What about p11, p12, etc.?  We will make the assumption
that the two die throws in our activity are `indepen-
dent' of each other.  What this means is that the proba-
bility of throwing an i on the first throw does NOT
DEPEND upon the result of the second throw, and the pro-
bability of throwing a j on the second throw does NOT
DEPEND upon the result of the first throw.  Or

    pi1 = pi2 = pi3 = pi4 = pi5 = pi6  for 1 <= i <= 6
and
    p1j = p2j = p3j = p4j = p5j = p6j  for 1 <= j <= 6

and since we already know that pi. = p.j = 1/6, we
deduce that pij = 1/36 for 1 <= i,j <= 6.



	




File:		probability
Author:		Bob Walton <walton@seas.harvard.edu>
Date:		See top of file.

The authors have placed this file in the public domain;
they make no warranty and accept no liability for this
file.

RCS Info (may not be true date or author):

    $Author: walton $
    $Date: 2012/12/11 12:37:02 $
    $RCSfile: probability,v $
    $Revision: 1.3 $
